<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
	"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">

<head>
<title>README.html</title>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8"/>

</head>

<body>

<h1 id="low-dimensional-interpretable-kernels-with-conic-discriminant-functions-for-classification">Low-dimensional Interpretable Kernels with Conic Discriminant Functions for Classification</h1>
<p>We propose several simple feature maps that lead to a collection of interpretable kernels with varying degrees of freedom. We make sure that the increase in the dimension of input data with each proposed feature map is extremely low, so that the resulting models can be trained quickly, and the obtained results can easily be interpreted. The details of this study is given in our <a href="./InterpretableConicKernels.pdf">paper</a>.</p>
<h1 id="required-packages">Required packages</h1>
<p>All our codes are implemented in Pyhton 3.7 and we use the following packages:</p>
<ol type="1">
<li><a href="https://numpy.org">Numpy</a></li>
<li><a href="https://scikit-learn.org/stable/index.html">Scikit-learn</a></li>
<li><a href="https://matplotlib.org/">Matplotlib</a></li>
</ol>
<h1 id="tutorials">Tutorials</h1>
<p>We provide the following tutorials to demonstrate our implementation.</p>
<ul>
<li><p>For the proposed feature maps, we refer to the pages <a href="./FeatureMaps.html">FeatureMaps</a> and <a href="./Kernels.html">Kernels</a>. We also provide the same tutorials as two notebooks, <a href="./FeatureMaps.ipynb">notebook one</a> and <a href="./Kernels.ipynb">notebook two</a>, respectively.</p></li>
<li><p>To obtain a row of Table 1, we refer to the page <a href="./Table_1.html">Table 1</a> or to the <a href="./Table_1.ipynb">notebook</a>.</p></li>
<li><p>To obtain a row of Table 2 and Table 3, we refer to the page <a href="./Table_2_3.html">Table_2_3</a> or to the <a href="./Table_2_3.ipynb">notebook</a>.</p></li>
<li><p>To obtain Figure 3, we refer to the page <a href="./Figure_3.html">Figure_3</a> or to the <a href="./Figure_3.ipynb">notebook</a>.</p></li>
<li><p>To obtain Figure 5, we refer to the page <a href="./Figure_5.html">Figure_5</a> or to the <a href="./Figure_5.ipynb">notebook</a>.</p></li>
</ul>
<h1 id="reproducing-our-results">Reproducing our results</h1>
<p>We provide the following scripts to reproduce the numerical experiments that we have reported in our paper.</p>
<ul>
<li><p><a href="./Table_1_Run.py">Table_1_Run.py</a></p></li>
<li><p><a href="./Table_2_3_Run.py">Table_2_3_Run.py</a></p></li>
<li><p><a href="./Figure_3_Run.py">Figure_3_Run.py</a></p></li>
<li><p><a href="./Figure_5_Phoneme_Run.py">Figure_5_Phoneme_Run.py</a></p></li>
<li><p><a href="./Figure_5_FourClass_Run.py">Figure_5_FourClass_Run.py</a></p></li>
<li><p><a href="./Figure_6_Run.py">Figure_6_Run.py</a></p></li>
</ul>
<h1 id="other-tutorials-with-various-machine-learning-problems-work-in-progress">Other tutorials with various machine learning problems (work-in-progress)</h1>
<ul>
<li><p><a href="./LogisticRegression.html">In this tutorial</a>, we explain how to apply the proposed feature maps with <strong>logistic regression</strong> on binary and multi-class classificiation problems. Notebook version of this tutorial can be found <a href="./LogisticRegression.ipynb">here</a>.</p></li>
<li><p>We also provide the following code snippets that reproduce Tables 2-3 and Figure 5 in our paper but this time with logistic regression.</p>
<ul>
<li><a href="./LR_Table_2_3_Run.py">Table_2_3_LR_Run.py</a></li>
<li><a href="./Figure_5_Phoneme_LR.py">Figure_5_Phoneme_LR_Run.py</a></li>
<li><a href="./Figure_5_FourClass_LR.py">Figure_5_FourClass_LR_Run.py</a></li>
</ul></li>
</ul>

</body>
</html>
