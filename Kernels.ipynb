{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Feature Maps and Kernels\n",
    "\n",
    "In this tutorial, we explain how to use the proposed feature maps and their associated kernels with SVM. We start with importing `numpy`, which is the only requirement for the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first feature map,  $\\phi_{p,1}(\\mathbf{x} ~|~ \\mathbf{a})$ maps the $d$-dimensional input data to $d+1$-dimensional feature space with a predefined anchor point $\\mathbf{a}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_p_1(X, anchor, p=1):\n",
    "    return np.hstack((X, (linalg.norm(X-anchor, axis=1, ord=p) ** p).reshape((len(X), 1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the associated kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_p_1(X1,X2,anchor,p=1):\n",
    "     return np.dot(X1, X2.T) + np.outer(linalg.norm(X1 - anchor, ord=p, axis=1)**p, linalg.norm(X2 - anchor, ord=p, axis=1)**p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import the linear SVM and the breast cancer wisconsin dataset (binary classification) from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3, random_state=42, stratify= y, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we choose the anchor point as the mean of the traing dataset and use the linear SVM after explicit mapping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.947\n"
     ]
    }
   ],
   "source": [
    "a=np.mean(X_train,axis=0)\n",
    "clf = LinearSVC(C=1, dual=False)\n",
    "clf = clf.fit(phi_p_1(X_train, anchor= a, p=1), y_train)\n",
    "predictions=clf.predict(phi_p_1(X_test,anchor=a,p=1))\n",
    "print(\"Test Accuracy: \", round(accuracy_score(y_test,predictions),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we apply scaling, the mean of the training data, and hence, the anchor point becomes the zero vector. The following code block is equivalent to the one above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.965\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def temp_phi_p_1(X, p=1):\n",
    "    return np.hstack((X, (linalg.norm(X, axis=1, ord=p) ** p).reshape((len(X), 1))))\n",
    "\n",
    "scaler=StandardScaler(with_std=False)\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)\n",
    "\n",
    "\n",
    "clf = LinearSVC(C=1, dual=False)\n",
    "clf = clf.fit(temp_phi_p_1(X_train_scaled, p=1), y_train)\n",
    "predictions=clf.predict(temp_phi_p_1(X_test_scaled,p=1))\n",
    "print(\"Test Accuracy: \", round(accuracy_score(y_test,predictions),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use kernels with parameters, `sklearn` requires a wrapper class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kernel():\n",
    "    def __init__(self,p=1):\n",
    "        self.p=p\n",
    "        \n",
    "    def k_p_1(self,X1,X2):\n",
    "         return np.dot(X1, X2.T) + np.outer(linalg.norm(X1, ord=self.p, axis=1), linalg.norm(X2, ord=self.p, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we use the given kernel with the scaled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.959\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "my_kernel=kernel(p=1)\n",
    "clf=SVC(kernel=my_kernel.k_p_1, C=1, random_state=42)\n",
    "clf=clf.fit(X_train_scaled,y_train)\n",
    "predictions=clf.predict(X_test_scaled)\n",
    "print(\"Test Accuracy: \", round(accuracy_score(y_test,predictions),3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our second feature map $\\phi_{p,d}(\\mathbf{x} ~|~ \\mathbf{a})$ maps the $d$-dimensional input data to $2d$-dimensional feature space with a predefined anchor point $\\mathbf{a}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_p_d(X, anchor, p=1):\n",
    "        return np.hstack((X, np.abs(X-anchor)**p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The associated kernel then becomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_p_d(X1,X2,anchor,p=1):\n",
    "    return np.dot(X1, X2.T) + np.dot(np.abs(X1 - anchor)**p, np.abs(X2 - anchor).T**p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous case, we use $\\phi_{p,d}(\\mathbf{x}_i ~|~ \\mathbf{a})$ and  its associated kernel on the same classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.965\n",
      "Test Accuracy:  0.942\n"
     ]
    }
   ],
   "source": [
    "def temp_phi_p_d(X, p=1):\n",
    "    return np.hstack((X, (linalg.norm(X, axis=1, ord=p) ** p).reshape((len(X), 1))))\n",
    "\n",
    "clf = LinearSVC(C=1, dual=False)\n",
    "clf = clf.fit(temp_phi_p_d(X_train_scaled, p=1), y_train)\n",
    "predictions=clf.predict(temp_phi_p_d(X_test_scaled,p=1))\n",
    "print(\"Test Accuracy: \", round(accuracy_score(y_test,predictions),3))\n",
    "\n",
    "\n",
    "class kernel():\n",
    "    def __init__(self,p=1):\n",
    "    \n",
    "        self.p=p\n",
    "        \n",
    "    def k_p_d(self,X1,X2):\n",
    "          return np.dot(X1, X2.T) + np.dot(np.abs(X1)**self.p, np.abs(X2).T**self.p)\n",
    "        \n",
    "        \n",
    "my_kernel=kernel(p=1)\n",
    "clf=SVC(kernel=my_kernel.k_p_d, C=1, random_state=42)\n",
    "clf = clf.fit(X_train_scaled, y_train)\n",
    "predictions=clf.predict(X_test_scaled)\n",
    "print(\"Test Accuracy: \", round(accuracy_score(y_test,predictions),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far the introduced feature maps use single anchor point for all input data. The following feature maps and kernels utilize multiple anchor points and uses different anchors for different inputs. \n",
    "\n",
    "Our first feature map that utilizes multiple anchor point is $\\phi_{p,1}(\\mathbf{x}_i ~|~ \\mathbf{a_i})$, where $A$ is a set of anchor points and $\\mathbf{a}_i= arg min_{\\mathbf{a} \\in A}\\{\\|\\mathbf{x}_i-\\mathbf{a}\\|_p\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_phi_p_1(X, anchors=[], p=1):\n",
    "    temp=[]\n",
    "    for a in anchors:\n",
    "        temp.append(linalg.norm(X-a,axis=1,ord=p)**p)\n",
    "    return np.hstack((X,np.min(temp,axis=0).reshape((len(X), 1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we choose two anchor points that are the sample averages for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.947\n"
     ]
    }
   ],
   "source": [
    "#get unique labels\n",
    "y_unique=np.unique(y_train)\n",
    "anchor_list=[]\n",
    "anchor_list.append(np.mean(X_train[y_train==y_unique[0]],axis=0))\n",
    "anchor_list.append(np.mean(X_train[y_train==y_unique[1]],axis=0))\n",
    "\n",
    "clf = LinearSVC(C=1, dual=False)\n",
    "clf=clf.fit(min_phi_p_1(X_train, anchors= anchor_list, p=1), y_train)\n",
    "predictions=clf.predict(min_phi_p_1(X_test, anchors= anchor_list, p=1))\n",
    "print(\"Test Accuracy: \", round(accuracy_score(y_test,predictions),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When multiple anchor points are introduced, the best practice is using the explicit feature maps. It is possible solve the dual SVM formulation by setting `dual = True`. This is suggessted for the datasets that contain more features than the training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.778\n"
     ]
    }
   ],
   "source": [
    "#suppress the convergence warning for LinearSVC\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "clf = LinearSVC(C=1, dual=True, random_state=42).fit(min_phi_p_1(X_train, anchors= anchor_list, p=1), y_train)\n",
    "print(\"Test Accuracy: \", round(accuracy_score(y_test,clf.predict(min_phi_p_1(X_test,anchors=anchor_list))),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also introduce the feature map $\\phi_{p,2}( \\mathbf{x}_i ~|~ \\mathbf{a}_i^{(1)},\\mathbf{a}_i^{(2)})$ where, $A_1,A_2$ are two sets of anchor points and $\\mathbf{a}_i^{(1)}= arg min_{\\mathbf{a} \\in A_1}\\{\\|\\mathbf{x}_i-\\mathbf{a}\\|_p\\}$, $\\mathbf{a}_i^{(2)}= arg min_{\\mathbf{a} \\in A_2}\\{\\|\\mathbf{x}_i-\\mathbf{a}\\|_p\\}$. The feature space for this map is $d+2$-dimensional. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_min_p_2(X,anchors=[],p=1):\n",
    "    temp = []\n",
    "    #begin: argmin \n",
    "    for a in anchors[0]:\n",
    "        temp.append(linalg.norm(X-a,axis=1,ord=p)**p)\n",
    "    temp=np.array(temp)\n",
    "    mins1=np.min(temp,axis=0)\n",
    "    mins1 = mins1 / np.std(mins1)\n",
    "    temp = []\n",
    "    for a in anchors[1]:\n",
    "        temp.append(linalg.norm(X - a, axis=1, ord=p)**p)\n",
    "    temp = np.array(temp)\n",
    "    mins2 = np.min(temp, axis=0)\n",
    "    mins2 = mins2/ np.std(mins2)\n",
    "    nz = [mins1 != 0, mins2 != 0]\n",
    "    d = np.all(nz, axis=0)\n",
    "    mins1[mins1==0]=np.mean( mins1[d])\n",
    "    mins2[mins2 == 0] = np.mean(mins2[d])\n",
    "    #end: argmin\n",
    "    X1=np.hstack((X, mins1.reshape((len(X), 1) )))\n",
    "    return   np.hstack((X1,mins2.reshape((len(X),1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, again we use two anchors as the means of the points that belong to different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.947\n"
     ]
    }
   ],
   "source": [
    "anchor_list=[[],[]]\n",
    "anchor_list[0].append(np.mean(X_train[y_train==y_unique[0]],axis=0))\n",
    "anchor_list[1].append(np.mean(X_train[y_train==y_unique[1]],axis=0))\n",
    "\n",
    "clf = LinearSVC(C=1, dual=False)\n",
    "clf=clf.fit(map_min_p_2(X_train, anchors= anchor_list, p=1), y_train)\n",
    "predictions=clf.predict(map_min_p_2(X_test,anchors=anchor_list,p=1))\n",
    "print(\"Test Accuracy: \", round(accuracy_score(y_test,predictions),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our last feature map is for the multi-class classification problems. We map $d$ dimensional input data to $d+M$-dimensional feature space, where $M$ is the number of classes in a given dataset.\n",
    "\n",
    "The feature map is, $\\phi_{p,M}(\\mathbf{x}_i~|~\\mathbf{a}_i^{(1)}, \\dots,\\mathbf{a}_i^{(M)})$ where ,$A_1,\\dots A_M$ are $M$ number of anchor sets and  $\\mathbf{a}_i^{(j)}= arg min_{\\mathbf{a} \\in A_j}\\{\\|\\mathbf{x}_i-\\mathbf{a}\\|_p\\}$, $j=1,\\dots, M.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_min_M_1(X, anchors,p=1):\n",
    "    X1=np.copy(X)\n",
    "    for anchors in anchors:\n",
    "        temp = []\n",
    "        for a in anchors:\n",
    "            temp.append(linalg.norm(X - a, axis=1, ord=p)**p)\n",
    "        temp = np.array(temp)\n",
    "        X1 = np.hstack((X1, (np.min(temp, axis=0).reshape((len(X), 1)))))\n",
    "    return X1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this feature map, we import `Iris` dataset from  `sklearn` and choose the anchor points as the means of the points that belong to three classes ($M=3)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3, random_state=42, stratify= y, shuffle=True)\n",
    "\n",
    "anchor_list=[[],[],[]]\n",
    "y_unique=np.unique(y_train)\n",
    "anchor_list[0].append(np.mean(X_train[y_train==y_unique[0]],axis=0))\n",
    "anchor_list[1].append(np.mean(X_train[y_train==y_unique[1]],axis=0))\n",
    "anchor_list[2].append(np.mean(X_train[y_train==y_unique[2]],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.933\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC(C=1, dual=False)\n",
    "clf = clf.fit(map_min_M_1(X_train, anchors= anchor_list, p=1), y_train)\n",
    "predictions= clf.predict(map_min_M_1(X_test,anchors=anchor_list,p=1))\n",
    "print(\"Test Accuracy: \", round(accuracy_score(y_test,predictions),3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
