{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 2 and 3\n",
    "\n",
    "This tutorial explains the experimental setup to obtain **one row** of Table 2 or Table 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC #Linear SVM for feature maps\n",
    "from sklearn.svm import SVC #Dual SVM for Kernels\n",
    "from time import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'FeatureMaps' and 'DataReader' imports are the modules that contain implementations of the proposed feature maps and the dataset importing procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FeatureMaps as maps\n",
    "import DataReader as DR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we give all of of the datasets and their names as commented code lines. A row of Table 2 and Table 3 can be obtained by simply changing the last two lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All datasets\n",
    "#datasets=[DR.Splice, DR.Wilt,DR.Guide1, DR.Spambase, DR.Phoneme, DR. Magic, DR.Adult ]\n",
    "# All dataset names\n",
    "#data_names=['Splice','Wilt', 'Guide 1', 'Spambase', 'Phoneme','Magic','Adult' ]\n",
    "\n",
    "datasets=[DR.Phoneme]\n",
    "data_names=['Phoneme']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code block creates lists of feature maps, kernels in the order of the columns in Table 1. When a feature map is removed from the list `mapping_functions` then, `p_vals`  list  should be arranged accordingly. Therefore, we suggest the reader to leave this code block as given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set mapping functions\n",
    "mapping_functions=[maps.linear, maps.phi_p_1,maps.phi_p_1,maps.phi_p_d,maps.phi_p_d]\n",
    "\n",
    "# Set p values according to the mapping functions in respected order in given Table 1\n",
    "# p value of the linear kernel is used as a dummy variable and others in respected order in given Table 1\n",
    "p_vals = [0,1,2,1,2]\n",
    "\n",
    "# Set mapping function an kernel names  in respected order in given Table 1\n",
    "kernel_names = ['LIN',r'$\\phi_{1,1}$',r'$\\phi_{2,1}$',r'$\\phi_{1,d}$',r'$\\phi_{2,d}$','POL','RBF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we create parameter sets for kernels and SVM model  along with the random state for splitting datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of POL  kernel parameters\n",
    "d_params = [2, 3, 4]\n",
    "# Set  of RBF kernel parameters\n",
    "g_params = np.power(10.0, range(-5, 5))\n",
    "\n",
    "# Set of  C parameters\n",
    "c_params = np.power(10.0, range(-5, 5))\n",
    "\n",
    "# Random seed for splitting the dataset\n",
    "random_state=42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store all of the performance metrics in the  dictionary named 'results' in order to print the obtained results in a readable format.  The metrics are stored by regarding the dataset-feature map and kernel orders, which are assigned above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary to store  all results\n",
    "results={'Dataset':[], 'Training Acc.':[], 'Test Acc.':[], 'Training Time':[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform grid search with stratified two-fold cross validation on each training part to find the best performing hyperparameters. Here, we also set the cross validation object to make sure each feature map and kernel use  same training and test parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(datasets)):\n",
    "    results['Dataset'].append(data_names[i])\n",
    "    X_train, X_test, y_train, y_test= datasets[i]()\n",
    "    #set dictionaries to store performance metrics\n",
    "    over_all_performance_metrics= {'Kernel': [], 'Training Acc': [], 'Test Acc': [], 'Training Time': []}\n",
    "    #2-fold cross validation object\n",
    "    inner_cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code block performs grid search with stratified two-fold cross validation  to find the best  performing hyperparameters for the linear and the proposed feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suppress the convergence warning for LinearSVC\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "for m in range(len(mapping_functions)):\n",
    "    over_all_performance_metrics['Kernel'].append(kernel_names[m])\n",
    "    acc_by_param = []\n",
    "    #begin: grid search \n",
    "    for ci in c_params:\n",
    "        all_acc = []\n",
    "       #begin: two-fold\n",
    "        for inner_train_index, inner_test_index in inner_cv.split(X_train, y_train):\n",
    "            #begin: scaling\n",
    "            scaler = StandardScaler()\n",
    "            X_inner_train = scaler.fit_transform(X_train[inner_train_index])\n",
    "            X_inner_test = scaler.transform(X_train[inner_test_index])\n",
    "            #end: scaling\n",
    "            y_inner_train, y_inner_test = y_train[inner_train_index], y_train[inner_test_index]\n",
    "            clf = LinearSVC(C=ci, dual=False).fit(mapping_functions[m](X_inner_train, p=p_vals[m]), y_inner_train)\n",
    "            all_acc.append(accuracy_score(y_inner_test, clf.predict(mapping_functions[m](X_inner_test, p=p_vals[m]))))\n",
    "        #end: two-fold\n",
    "        acc_by_param.append(np.mean(all_acc))\n",
    "    #end: grid search \n",
    "    #get best hyperparameters\n",
    "    best_c = c_params[np.argmax(acc_by_param)]\n",
    "    scaler = StandardScaler()\n",
    "    #being: scaling\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled=scaler.transform(X_test)\n",
    "    #end: scaling\n",
    "    s = time()\n",
    "    XD_train = mapping_functions[m](X_train_scaled,p=p_vals[m])\n",
    "    clf = LinearSVC(C=best_c, dual=False).fit(XD_train, y_train)\n",
    "    over_all_performance_metrics['Training Time'].append( round(time() - s, 4))\n",
    "    over_all_performance_metrics['Training Acc'].append(round(100*accuracy_score(y_train, clf.predict(XD_train)),2))\n",
    "    over_all_performance_metrics['Test Acc'].append(round(100*accuracy_score(y_test, clf.predict(mapping_functions[m](X_test_scaled, p=p_vals[m]))),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code block, performs grid search with stratified two-fold cross validation  to find the best  performing hyperparameters for the POL kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_all_performance_metrics['Kernel'].append('POL')\n",
    "acc_by_param = {'ci': [], 'di': [], 'inner_test_acc': []}\n",
    "#begin: grid search\n",
    "for ci in c_params:\n",
    "    for di in d_params:\n",
    "        all_acc = []\n",
    "        #begin: two-fold\n",
    "        for inner_train_index, inner_test_index in inner_cv.split(X_train, y_train):\n",
    "            #begin: scaling\n",
    "            scaler = StandardScaler()\n",
    "            X_inner_train = scaler.fit_transform(X_train[inner_train_index])\n",
    "            X_inner_test = scaler.transform(X_train[inner_test_index])\n",
    "            #end:  scaling\n",
    "            y_inner_train, y_inner_test = y_train[inner_train_index], y_train[inner_test_index]\n",
    "            clf = SVC(kernel='poly', C=ci, degree=di).fit(X_inner_train, y_inner_train)\n",
    "            all_acc.append(accuracy_score(y_inner_test, clf.predict(X_inner_test)))\n",
    "        #end: two fold\n",
    "        acc_by_param['ci'].append(ci)\n",
    "        acc_by_param['di'].append(di)\n",
    "        acc_by_param['inner_test_acc'].append(np.mean(all_acc))\n",
    "#end: grid search \n",
    "#get best hyperparameters\n",
    "best_ind = np.argmax(acc_by_param['inner_test_acc'])\n",
    "best_c, best_d = acc_by_param['ci'][best_ind], acc_by_param['di'][best_ind]\n",
    "#begin: scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = scaler.fit_transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "#end: scaling\n",
    "s = time()\n",
    "clf = SVC(kernel='poly', C=best_c, degree=best_d).fit(X_train_scale, y_train)\n",
    "over_all_performance_metrics['Training Time'].append(round(time() - s, 4))\n",
    "over_all_performance_metrics['Training Acc'].append(round(100*accuracy_score(y_train, clf.predict(X_train_scale ),2)))\n",
    "over_all_performance_metrics['Test Acc'].append(round(100*accuracy_score(y_test, clf.predict(X_test_scale),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code block, performs grid search with stratified two-fold cross validation  to find the best  performing hyperparameters for the RBF kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_all_performance_metrics['Kernel'].append('RBF')\n",
    "acc_by_param = {'ci': [], 'gi': [], 'inner_test_acc': []}\n",
    "#begin: grid search\n",
    "for ci in c_params:\n",
    "    for gi in g_params:\n",
    "        all_acc = []\n",
    "        #begin: two-fold\n",
    "        for inner_train_index, inner_test_index in inner_cv.split(X_train, y_train):\n",
    "            #begin: scaling\n",
    "            scaler = StandardScaler()\n",
    "            X_inner_train = scaler.fit_transform(X_train[inner_train_index])\n",
    "            X_inner_test = scaler.transform(X_train[inner_test_index])\n",
    "            #end: scaling\n",
    "            y_inner_train, y_inner_test = y_train[inner_train_index], y_train[inner_test_index]\n",
    "            clf = SVC(kernel='rbf', C=ci, gamma=gi).fit(X_inner_train, y_inner_train)\n",
    "            all_acc.append(accuracy_score(y_inner_test, clf.predict(X_inner_test)))\n",
    "        #end: two-fold\n",
    "        acc_by_param['ci'].append(ci)\n",
    "        acc_by_param['gi'].append(gi)\n",
    "        acc_by_param['inner_test_acc'].append(np.mean(all_acc))\n",
    "#end: grid search \n",
    "#get best hyperparameters\n",
    "best_ind = np.argmax(acc_by_param['inner_test_acc'])\n",
    "best_c, best_g = acc_by_param['ci'][best_ind], acc_by_param['gi'][best_ind]\n",
    "#begin: scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = scaler.fit_transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "#end: scaling\n",
    "s = time()\n",
    "clf = SVC(kernel='rbf', C=best_c, gamma=best_g).fit(X_train_scale, y_train)\n",
    "over_all_performance_metrics['Training Time'].append(round(time() - s, 4))\n",
    "over_all_performance_metrics['Training Acc'].append(round(100 * accuracy_score(y_train, clf.predict(X_train_scale), 2)))\n",
    "over_all_performance_metrics['Test Acc'].append(round(100 * accuracy_score(y_test, clf.predict(X_test_scale), 2)))\n",
    "results['Training Time'].append(over_all_performance_metrics['Training Time'])\n",
    "results['Training Acc.'].append(over_all_performance_metrics['Training Acc'])\n",
    "results['Test Acc.'].append(over_all_performance_metrics['Test Acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code block prints the performance metrics in a readeable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Table 2: Test Accuracies\n",
      "\n",
      "***Phoneme\n",
      "LIN\t75.46\t\t$\\phi_{1,1}$\t73.61\t\t$\\phi_{2,1}$\t74.29\t\t$\\phi_{1,d}$\t76.82\t\t$\\phi_{2,d}$\t76.57\t\tPOL\t78.0\t\tRBF\t88.0\t\t\n"
     ]
    }
   ],
   "source": [
    "print('***** Table 2: Test Accuracies')\n",
    "n_datasets=len(datasets)\n",
    "n_kenels=len(kernel_names)\n",
    "for d in range(n_datasets):\n",
    "    print()\n",
    "    print('***'+ results['Dataset'][d])\n",
    "    temp=''\n",
    "    for k in range(n_kenels):\n",
    "        temp+=kernel_names[k] +'\\t'+ str(results['Test Acc.'][d][k])+ '\\t'+ '\\t'\n",
    "    print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Table 3: Training Times in Seconds\n",
      "\n",
      "***Phoneme\n",
      "LIN\t0.0023\t\t$\\phi_{1,1}$\t0.0028\t\t$\\phi_{2,1}$\t0.0026\t\t$\\phi_{1,d}$\t0.0053\t\t$\\phi_{2,d}$\t0.0041\t\tPOL\t143.6466\t\tRBF\t0.3508\t\t\n"
     ]
    }
   ],
   "source": [
    "print('***** Table 3: Training Times in Seconds')\n",
    "n_datasets=len(datasets)\n",
    "n_kenels=len(kernel_names)\n",
    "for d in range(n_datasets):\n",
    "    print()\n",
    "    print('***'+ results['Dataset'][d])\n",
    "    temp=''\n",
    "    for k in range(n_kenels):\n",
    "        temp+=kernel_names[k] +'\\t'+ str(results['Training Time'][d][k])+ '\\t'+ '\\t'\n",
    "\n",
    "    print(temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
