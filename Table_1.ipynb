{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 1 \n",
    "\n",
    "This tutorial explains the experimental setup to obtain **one row** of Table 1 in our paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC #Linear SVM for feture maps\n",
    "from sklearn.svm import SVC #Dual SVM for Kernels\n",
    "from time import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'FeatureMaps' and 'DataReader' imports are the modules that contain implementations of the proposed feature maps and the dataset importing procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FeatureMaps as maps\n",
    "import DataReader as DR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we give all of of the datasets.  A row of Table 1 can be obtained  by simply changing the last two lines below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All datasets\n",
    "#datasets= [DR.australian,DR.fourclass,DR.ionosphere,DR.heart,DR.pima,DR.wprognostic,DR.bupa,DR.fertility,DR.wdiagnostic]\n",
    "\n",
    "# All dataset names\n",
    "#data_names=['Australian','Fourclass', 'Ionosphere', 'Heart', 'PIMA', 'W. Prognostic','Bupa', 'Fertility', 'W. Diagnostic' ]\n",
    "\n",
    "datasets=[DR.australian]\n",
    "data_names=['Australian']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code block creates lists of feature maps, kernels in the order of the columns in Table 1. When a feature map is removed from the list `mapping_functions` then, `p_vals`  list  should be arranged accordingly. Therefore, we suggest the reader to leave this code block as given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping funtions\n",
    "mapping_functions=[maps.linear, maps.phi_p_1,maps.phi_p_1,maps.phi_p_d,maps.phi_p_d]\n",
    "\n",
    "# p values\n",
    "# p value of the linear kernel is used as a dummy variable\n",
    "p_vals= [0,1,2,1,2]\n",
    "\n",
    "# Mapping and kernel names\n",
    "kernel_names=['LIN',r'$\\phi_{1,1}$',r'$\\phi_{2,1}$',r'$\\phi_{1,d}$',r'$\\phi_{2,d}$','POL','RBF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we create parameter sets for kernels and SVM model along with the random state for splitting the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of POL kernel degree pameters \n",
    "d_params = [2, 3, 4]\n",
    "\n",
    "# Set of  RBF kernel gamma parameters\n",
    "g_params = np.power(10.0, range(-5, 5))\n",
    "\n",
    "# Set of C parameters (penalty parameter)\n",
    "c_params = np.power(10.0, range(-5, 5))\n",
    "\n",
    "# Random seed for spliting the dataset\n",
    "random_state=42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store all of the performance metrics in the  dictionary named 'results' in order to print the obtained results in a readable format.  The metrics are stored by regarding the dataset-feature map and kernel orders, which are assigned above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary to store  all results\n",
    "results={'Dataset':[], 'Training Acc.':[], 'Test Acc.':[], 'Training Time':[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform stratified 10-fold cross validation for each given dataset. The best performing hyperparameters are found by applying grid search with stratified two-fold cross validation on each training part. Here, we also set the cross validation objects to make sure each feature map and kernel use same training and test parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sibirbil/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass n_features=14 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for  i in range(len(datasets)):\n",
    "    X,y=datasets[i]()\n",
    "    # A dictionary to store performance metrics\n",
    "    average_performance_metrics = {'Kernel': [], 'Training Acc': [], 'Test Acc': [], 'Training Time': []}\n",
    "    # 10-fold cros validation object \n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "    # 2-fold cross validation object\n",
    "    inner_cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code block, performs  stratified 10-fold cross validation for the proposed feature maps including  the linear. It also finds the best  performing hyperparameters by applying grid search with stratified two-fold cross validation on each training part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suppress the convergence warning for LinearSVC\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "for m in range(len(mapping_functions)):\n",
    "    average_performance_metrics['Kernel'].append(kernel_names[m])\n",
    "    performance_metrics = {'Train_Acc': [], 'Test_Acc': [], 'Train_Time': []}\n",
    "    #begin: 10-fold\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        acc_by_param = []\n",
    "        #begin: grid search\n",
    "        for ci in c_params:\n",
    "            all_acc = []\n",
    "            #begin: two-fold\n",
    "            for inner_train_index, inner_test_index in inner_cv.split(X_train, y_train):\n",
    "                #begin: scaling\n",
    "                scaler = StandardScaler()\n",
    "                X_inner_train = scaler.fit_transform(X_train[inner_train_index])\n",
    "                X_inner_test = scaler.transform(X_train[inner_test_index])\n",
    "                #end: scaling\n",
    "                y_inner_train, y_inner_test = y_train[inner_train_index], y_train[inner_test_index]\n",
    "                clf = LinearSVC(C=ci, dual=False).fit(mapping_functions[m](X_inner_train, p=p_vals[m]), y_inner_train)\n",
    "                all_acc.append(accuracy_score(y_inner_test, clf.predict(mapping_functions[m](X_inner_test, p=p_vals[m]))))\n",
    "            #end: two-fold\n",
    "            acc_by_param.append(np.mean(all_acc))\n",
    "        #end: grid search\n",
    "        #get best hyperparameters\n",
    "        best_c = c_params[np.argmax(acc_by_param)]\n",
    "        #begin: scaling\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled=scaler.fit_transform(X_train)\n",
    "        X_test_scaled=scaler.transform(X_test)\n",
    "        #end: scaling\n",
    "        s = time()\n",
    "        XD_train = mapping_functions[m](X_train_scaled, p=p_vals[m])\n",
    "        clf = LinearSVC(C=best_c, dual=False).fit(XD_train, y_train)\n",
    "        performance_metrics['Train_Time'].append(round(time() - s, 4))\n",
    "        performance_metrics['Train_Acc'].append(accuracy_score(y_train, clf.predict(XD_train)))\n",
    "        performance_metrics['Test_Acc'].append(accuracy_score(y_test, clf.predict(mapping_functions[m](X_test_scaled, p=p_vals[m]))))\n",
    "    #end: 10-fold\n",
    "    average_performance_metrics['Training Acc'].append(round(100 * np.mean(performance_metrics['Train_Acc']), 2))\n",
    "    average_performance_metrics['Test Acc'].append(round(100 * np.mean(performance_metrics['Test_Acc']), 2))\n",
    "    average_performance_metrics['Training Time'].append( round(np.mean(performance_metrics['Train_Time']), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code block performs the stratified 10-fold cross validation for POL kernel and finds the best performing parameters by applying grid search\n",
    "with stratified two-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_performance_metrics['Kernel'].append('POL')\n",
    "performance_metrics = {'Train_Acc': [], 'Test_Acc': [], 'Train_Time': []}\n",
    "#begin: 10-fold\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    acc_by_param = {'ci': [], 'di': [], 'inner_test_acc': []}\n",
    "    #begin: grid search\n",
    "    for ci in c_params:\n",
    "        for di in d_params:\n",
    "            all_acc = []\n",
    "            #begin: two-fold\n",
    "            for inner_train_index, inner_test_index in inner_cv.split(X_train, y_train):\n",
    "                #begin: scaling\n",
    "                scaler = StandardScaler()\n",
    "                X_inner_train = scaler.fit_transform(X_train[inner_train_index])\n",
    "                X_inner_test = scaler.transform(X_train[inner_test_index])\n",
    "                #end: scaling\n",
    "                y_inner_train, y_inner_test = y_train[inner_train_index], y_train[inner_test_index]\n",
    "                clf = SVC(kernel='poly', C=ci, degree=di).fit(X_inner_train, y_inner_train)\n",
    "                all_acc.append(accuracy_score(y_inner_test, clf.predict(X_inner_test)))\n",
    "            #end: two-fold\n",
    "            acc_by_param['ci'].append(ci)\n",
    "            acc_by_param['di'].append(di)\n",
    "            acc_by_param['inner_test_acc'].append(np.mean(all_acc))\n",
    "    #end: grid search\n",
    "    #get best hyperparameters\n",
    "    best_ind = np.argmax(acc_by_param['inner_test_acc'])\n",
    "    best_c, best_d = acc_by_param['ci'][best_ind], acc_by_param['di'][best_ind]\n",
    "    #begin: scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scale = scaler.fit_transform(X_train)\n",
    "    X_test_scale = scaler.transform(X_test)\n",
    "    #end: scaling\n",
    "    s = time()\n",
    "    clf = SVC(kernel='poly', C=best_c, degree=best_d).fit(X_train_scale, y_train)\n",
    "    performance_metrics['Train_Time'].append(round(time() - s, 4))\n",
    "    performance_metrics['Train_Acc'].append(accuracy_score(y_train, clf.predict(X_train_scale)))\n",
    "    performance_metrics['Test_Acc'].append(accuracy_score(y_test, clf.predict(X_test_scale)))\n",
    " #end: 10-fold\n",
    "average_performance_metrics['Training Acc'].append(round(100 * np.mean(performance_metrics['Train_Acc']), 2))\n",
    "average_performance_metrics['Test Acc'].append(round(100 * np.mean(performance_metrics['Test_Acc']), 2))\n",
    "average_performance_metrics['Training Time'].append(round(np.mean(performance_metrics['Train_Time']), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code block performs the stratified 10-fold cross validation for RBF kernel and finds the best performing parameters by applying grid search\n",
    "with stratified two-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_performance_metrics['Kernel'].append('RBF')\n",
    "performance_metrics = {'Train_Acc': [], 'Test_Acc': [], 'Train_Time': []}\n",
    "#begin: 10-fold\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    acc_by_param = {'ci': [], 'gi': [], 'inner_test_acc': []}\n",
    "    #begin: grid search\n",
    "    for ci in c_params:\n",
    "        for gi in g_params:\n",
    "            all_acc = []\n",
    "            #begin: two-fold\n",
    "            for inner_train_index, inner_test_index in inner_cv.split(X_train, y_train):\n",
    "                #begin: scaling\n",
    "                scaler = StandardScaler()\n",
    "                X_inner_train = scaler.fit_transform(X_train[inner_train_index])\n",
    "                X_inner_test = scaler.transform(X_train[inner_test_index])\n",
    "                #end: scaling\n",
    "                y_inner_train, y_inner_test = y_train[inner_train_index], y_train[inner_test_index]\n",
    "                clf = SVC(kernel='rbf', C=ci, gamma=gi).fit(X_inner_train, y_inner_train)\n",
    "                all_acc.append(accuracy_score(y_inner_test, clf.predict(X_inner_test)))\n",
    "            #end: two-fold\n",
    "            acc_by_param['ci'].append(ci)\n",
    "            acc_by_param['gi'].append(gi)\n",
    "            acc_by_param['inner_test_acc'].append(np.mean(all_acc))\n",
    "    #end: grid search\n",
    "    #get best hyperparameters\n",
    "    best_ind = np.argmax(acc_by_param['inner_test_acc'])\n",
    "    best_c, best_g = acc_by_param['ci'][best_ind], acc_by_param['gi'][best_ind]\n",
    "    #begin: scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scale = scaler.fit_transform(X_train)\n",
    "    X_test_scale = scaler.transform(X_test)\n",
    "    #end: scaling\n",
    "    s = time()\n",
    "    clf = SVC(kernel='rbf', C=best_c, gamma=best_g).fit(X_train_scale, y_train)\n",
    "    performance_metrics['Train_Time'].append(round(time() - s, 4))\n",
    "    performance_metrics['Train_Acc'].append(accuracy_score(y_train, clf.predict(X_train_scale)))\n",
    "    performance_metrics['Test_Acc'].append(accuracy_score(y_test, clf.predict(X_test_scale)))\n",
    "#end: 10-fold\n",
    "average_performance_metrics['Training Acc'].append(round(100 * np.mean(performance_metrics['Train_Acc']), 2))\n",
    "average_performance_metrics['Test Acc'].append(round(100 * np.mean(performance_metrics['Test_Acc']), 2))\n",
    "average_performance_metrics['Training Time'].append(round(np.mean(performance_metrics['Train_Time']), 4))\n",
    "\n",
    "#store all results\n",
    "results['Dataset'].append(data_names[i])\n",
    "results['Training Acc.'].append(average_performance_metrics['Training Acc'])\n",
    "results['Test Acc.'].append(average_performance_metrics['Test Acc'])\n",
    "results['Training Time'].append(average_performance_metrics['Training Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code block prints the performance metrics in a readeable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Table 1: Average Test Accuracies\n",
      "\n",
      "***Australian\n",
      "LIN\t86.81\t\t$\\phi_{1,1}$\t86.81\t\t$\\phi_{2,1}$\t86.67\t\t$\\phi_{1,d}$\t86.67\t\t$\\phi_{2,d}$\t86.09\t\tPOL\t84.2\t\tRBF\t85.51\t\t\n"
     ]
    }
   ],
   "source": [
    "print('***** Table 1: Average Test Accuracies')\n",
    "n_datasets=len(datasets)\n",
    "n_kenels=len(kernel_names)\n",
    "for d in range(n_datasets):\n",
    "    print()\n",
    "    print('***'+ results['Dataset'][d])\n",
    "    temp=''\n",
    "    for k in range(n_kenels):\n",
    "        temp+=kernel_names[k] +'\\t'+ str(results['Test Acc.'][d][k])+ '\\t'+ '\\t'\n",
    "\n",
    "    print(temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
